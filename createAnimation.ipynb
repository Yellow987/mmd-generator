{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with song: PV002 - World is Mine\n",
      "added 146 frames. Total frames is now: 153\n",
      "querying for similar poses for song: PV002 - World is Mine at frame: 4013\n",
      "PV002 - World is Mine-4159\n",
      "found match: PV021 - Beware of the Miku Miku Germs at frame: 5000.0 with distance: 0.98961252\n",
      "added 190 frames. Total frames is now: 350\n",
      "querying for similar poses for song: PV021 - Beware of the Miku Miku Germs at frame: 5000.0\n",
      "PV021 - Beware of the Miku Miku Germs-5190\n",
      "found match: PV626 - Weekender Girl at frame: 1013.0 with distance: 0.988558233\n",
      "added 224 frames. Total frames is now: 581\n",
      "querying for similar poses for song: PV626 - Weekender Girl at frame: 1013.0\n",
      "PV626 - Weekender Girl-1237\n",
      "found match: PV832 - Hand in Hand at frame: 1262.0 with distance: 0.980824113\n",
      "added 147 frames. Total frames is now: 735\n",
      "querying for similar poses for song: PV832 - Hand in Hand at frame: 1262.0\n",
      "PV832 - Hand in Hand-1409\n",
      "found match: PV932 - Hand in Hand at frame: 1409.0 with distance: 0.999407589\n",
      "added 217 frames. Total frames is now: 959\n",
      "querying for similar poses for song: PV932 - Hand in Hand at frame: 1409.0\n",
      "PV932 - Hand in Hand-1626\n",
      "found match: PV915 - A Single Red Leaf at frame: 6371.0 with distance: 0.975076437\n",
      "added 164 frames. Total frames is now: 1130\n",
      "querying for similar poses for song: PV915 - A Single Red Leaf at frame: 6371.0\n",
      "PV915 - A Single Red Leaf-6535\n",
      "found match: PV225 - Yume Yume at frame: 2521.0 with distance: 0.969177663\n",
      "added 158 frames. Total frames is now: 1295\n",
      "querying for similar poses for song: PV225 - Yume Yume at frame: 2521.0\n",
      "PV225 - Yume Yume-2679\n",
      "found match: PV311 - World's End Dancehall Live Mode at frame: 1285.0 with distance: 0.991013288\n",
      "added 229 frames. Total frames is now: 1531\n",
      "querying for similar poses for song: PV311 - World's End Dancehall Live Mode at frame: 1285.0\n",
      "PV311 - World's End Dancehall Live Mode-1514\n",
      "found match: PV901 - Strangers at frame: 3725.0 with distance: 0.985704839\n",
      "added 144 frames. Total frames is now: 1682\n",
      "62912\n",
      "27676\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from Utility import df_ops, music_ops, vmd_ops, io_ops, interpolate, cloud_ops\n",
    "import pandas as pd\n",
    "import os \n",
    "import pinecone\n",
    "import pymeshio.common\n",
    "import numpy as np\n",
    "\n",
    "class DanceClip:\n",
    "  def __init__(self, pathToVmd, pathToInterpolatedVmd, startFrame, numberOfFrames):\n",
    "    self.pathToVmd = pathToVmd\n",
    "    self.pathToInterpolatedVmd = pathToInterpolatedVmd\n",
    "    self.startFrame = startFrame\n",
    "    self.numberOfFrames = numberOfFrames\n",
    "\n",
    "def queryForSimilarPoses(pinecone, vector, songNamesToExclude):\n",
    "  index = pinecone.Index(os.getenv('PINECONE_INDEX_NAME'))\n",
    "  songs = index.query(\n",
    "    vector=vector,\n",
    "    filter={\n",
    "      \"animationName\": { \"$nin\": songNamesToExclude }\n",
    "    },\n",
    "    top_k=1,\n",
    "    include_metadata=True\n",
    "  )\n",
    "  matchedSongName = songs.matches[0].metadata['animationName']\n",
    "  frameNumberOfMatchedSong = songs.matches[0].metadata['frameNumber']\n",
    "  distance = songs.matches[0]['score']\n",
    "  print(\"found match: \" + matchedSongName + \" at frame: \" + str(frameNumberOfMatchedSong) + \" with distance: \" + str(distance))\n",
    "  return matchedSongName, frameNumberOfMatchedSong\n",
    "\n",
    "def appendFramesPreservingCenter(df, dfToAppend, buffer=0):\n",
    "  if df.empty:\n",
    "    lastPositionOfDf = pymeshio.common.Vector3(0, 0, 0)\n",
    "  else:\n",
    "    lastPositionOfDfIdx = df[df['name'] == 'センター']['frame'].idxmax()\n",
    "    lastPositionOfDf = df.iloc[lastPositionOfDfIdx]['position']\n",
    "\n",
    "  try:\n",
    "    firstPositionOfDfToAppendIdx = dfToAppend[dfToAppend['name'] == 'センター']['frame'].idxmin()\n",
    "    firstPositionOfDfToAppend = dfToAppend.iloc[firstPositionOfDfToAppendIdx]['position']\n",
    "  except:\n",
    "    if dfToAppend.empty:\n",
    "      print(\"dfToAppend is empty\")\n",
    "    if len(dfToAppend[dfToAppend['name'] == 'センター']) == 0:\n",
    "      print(\"No rows with name 'センター' in dfToAppend\")\n",
    "    print(\"Index to access:\", firstPositionOfDfToAppendIdx)\n",
    "    print(\"Length of dfToAppend:\", len(dfToAppend))\n",
    "    raise Exception(\"Error\")\n",
    "\n",
    "  differenceInPos = firstPositionOfDfToAppend - lastPositionOfDf\n",
    "  differenceInPos.y = 0\n",
    "\n",
    "  positionBoneNames = ['センター', '右足ＩＫ', '左足ＩＫ']\n",
    "  dfToAppendWithAdjustedPositions = dfToAppend.copy()\n",
    "  dfToAppendWithAdjustedPositions['position'] = np.where(dfToAppendWithAdjustedPositions['name'].isin(positionBoneNames), \n",
    "                                  dfToAppendWithAdjustedPositions['position'] - differenceInPos,\n",
    "                                  dfToAppendWithAdjustedPositions['position'])\n",
    "  return df_ops.appendFrames(df, dfToAppendWithAdjustedPositions, buffer=buffer)\n",
    "\n",
    "def getVectorFromVectorId(pinecone, songName, framenumber):\n",
    "  vectorId = songName + \"-\" + str(int(framenumber))\n",
    "  print(vectorId)\n",
    "  index = pinecone.GRPCIndex(os.getenv('PINECONE_INDEX_NAME'))\n",
    "  fetchVectorId = index.fetch([vectorId])\n",
    "  return fetchVectorId['vectors'][vectorId]['values']\n",
    "\n",
    "def generateDance(numberOfFrames):\n",
    "  INPUT_FOLDER = 'inputData'\n",
    "  pinecone = cloud_ops.initPinecone()\n",
    "  sum = 0\n",
    "  end = numberOfFrames\n",
    "  newAnimation = pd.DataFrame()\n",
    "  newInterpolatedAnimation = pd.DataFrame()\n",
    "  newSongName = random.choice([entry for entry in os.listdir(INPUT_FOLDER) if os.path.isdir(os.path.join(INPUT_FOLDER, entry))])\n",
    "  print(\"starting with song: \" + newSongName)\n",
    "  pastSongs = [newSongName]\n",
    "\n",
    "  while sum < end:\n",
    "    if sum != 0:\n",
    "      print(\"querying for similar poses for song: \" + prevSongName + \" at frame: \" + str(startingFrameOfNewFrames))\n",
    "      poseVector = getVectorFromVectorId(pinecone, prevSongName, startingFrameOfNewFrames + numberOfNewFramesToAdd)\n",
    "      newSongName, frameNumberOfMatchedSong = queryForSimilarPoses(pinecone, poseVector, pastSongs)\n",
    "      pastSongs.append(newSongName)\n",
    "\n",
    "    vmd = [f for f in os.listdir(INPUT_FOLDER + \"\\\\\" + newSongName) if f.endswith('.vmd')][0]\n",
    "    df = vmd_ops.getDfFromVmdFileName(INPUT_FOLDER + \"\\\\\" + newSongName + \"\\\\\" + vmd)\n",
    "    numberOfNewFramesToAdd = random.randint(120, 240)\n",
    "    startingFrameOfNewFrames = frameNumberOfMatchedSong if sum != 0 else random.randint(0, df_ops.getLastFrame(df) - numberOfNewFramesToAdd)\n",
    "    newAnimation = appendFramesPreservingCenter(newAnimation, df_ops.parseFramesFromDf(df, startingFrameOfNewFrames, startingFrameOfNewFrames + numberOfNewFramesToAdd), bufferFrames)\n",
    "    if viewInterpolation:\n",
    "      interpolatedDf = df_ops.loadDfFromFeather(INPUT_FOLDER + \"\\\\\" + newSongName + \"\\\\interpolatedMotion.feather\")\n",
    "      newInterpolatedAnimation = df_ops.appendFrames(newInterpolatedAnimation, df_ops.parseFramesFromDf(interpolatedDf, startingFrameOfNewFrames, startingFrameOfNewFrames + numberOfNewFramesToAdd), bufferFrames)\n",
    "    print(\"added \" + str(numberOfNewFramesToAdd) + \" frames. Total frames is now: \" + str(df_ops.getLastFrame(newAnimation)))\n",
    "\n",
    "    sum += numberOfNewFramesToAdd\n",
    "    prevSongName = newSongName\n",
    "\n",
    "  vmd_ops.saveDfToVmdFile(newAnimation, savePath + \"\\\\\" + saveName + \".vmd\")\n",
    "  if viewInterpolation:\n",
    "    vmd_ops.saveDfToVmdFile(newInterpolatedAnimation, savePath + \"\\\\\" + saveName + \"-interpolated-DEBUG.vmd\")\n",
    "\n",
    "def generateVmdAnimationFromDance(animationClips, savePath, saveName, bufferFrames=0, viewInterpolation=False):\n",
    "  vmd_ops.saveDfToVmdFile(newAnimation, savePath + \"\\\\\" + saveName + \".vmd\")\n",
    "  if viewInterpolation:\n",
    "    vmd_ops.saveDfToVmdFile(newInterpolatedAnimation, savePath + \"\\\\\" + saveName + \"-interpolated-DEBUG.vmd\")\n",
    "\n",
    "generateDance(1500, 'outputMotions', 'correct-center', bufferFrames=7, viewInterpolation=True)\n",
    "generateVmdAnimationFromDance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
